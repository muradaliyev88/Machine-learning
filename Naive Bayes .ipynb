{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "\n",
    "\n",
    "**Naive Bayes Sinifləndirici adını İngilis riyaziyyatçı Tomas Bayes'dən (1701 - 7 Nisan 1761) alır.Naive Bayes, müəyyən bir sinifə aid bir məlumat nöqtəsinin hansı sinifə aid olma  ehtimalını hesablayan proqnozlar verən bir modelidir.Maşın öyrənməsində Naive Bayes sinifləndirici, Bayes teoremini özəlliklər arasında müstəqil fərziyyələri tətbiq etməyə əsaslanan siniflərə aid ehtimallar hesablayan  təlimat öyrənmə alt sinifindədir.Sinifləndirmə,özəlliklər və sinif ehtimallarını nəzərə alaraq ən çox ehtimal olunan sinif seçərək aparılır.**\n",
    "\n",
    "_Bayes teoremindən istifadə edərək B-nin meydana gəldiyini nəzərə alsaq A olma ehtimalını tapa bilərik. Burada B dəlil, A isə hipotezdir. Burada edilən ehtimal, proqnozlaşdırıcıların / xüsusiyyətlərin müstəqil olmasıdır. Yəni müəyyən bir xüsusiyyətin olması digərinə təsir etmir. Buna görə sadə adlanır._\n",
    "## $P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_İki etiket arasında ehtimalı istənilən verilənin ehtimalını hesablmaq istəyiriksə əvvəlcə siniflərə L1 və L2 adlandıraq daha sonra hər etiket üçün sonrakı ehtimalların nisbətini hesablamaq lazımdır:_\n",
    "\n",
    "## $\\frac{P(L_1 |özəlliklər)(P|L_1)}{P(L_1 |özəlliklər)(P|L_1)}=\\frac{P(özəlliklər |L_1) P(L_1)}{P(özəlliklər  | L_2)P(L_2)}$\n",
    "\n",
    "_Hər bir sinif üçün bu generativ model ilə hər hansı bir məlumat nöqtəsi üçün P xüsusiyyətlərinin L1 ehtimalını hesablamaq üçün sadə bir tarifimiz var və buna görə sonra gələnin nisbətini tez bir şəkildə hesablaya bilərik və hər hansı bir nöqtənin hansı etiketə uyğun olacağını müəyyənləşdirə bilərik. \n",
    "\n",
    "# Naive Bayes Sinifləndiricinin növləri:\n",
    "\n",
    "### Multinomial Naive Bayes:\n",
    "_Bu, əsasən mətinlərin idman, siyasət, texnologiya və s. Kateqoriyasına aid olub-olmaması üçün istifadə olunur._\n",
    "\n",
    "### Bernoulli Naive Bayes:\n",
    "_Bu multinomial naive bayesə bənzəyir, lakin proqnoz verənlər `boolean` dəyişkənlərdir. Sinif dəyişkənlərini tapmaq üçün istifadə etdiyimiz parametrlər yalnızca bəli və ya yox olur məsələn, mətndə bir söz meydana gəldi və ya gəlmədi_.\n",
    "\n",
    "### Gaussian Naive Bayes:\n",
    "_Proqnoz verənlər davamlı bir dəyəri aldığında və diskret olmadıqda, bu dəyərlərin gaussian distributordan nümunələndiyini varsayırıq._\n",
    "\n",
    "Naive Bayes alqoritmləri əsasən həssaslıq, spam filtirlənməsində, tövsiyə sistemlərində və s. istifadə olunur. Təxminlər sürətlə həyata keçməkdədir, lakin ən böyük çatışmazlığı proqnozçıların sərbəst olmamasıdır. Real həyatda əksər hallarda, proqnozlaşdırıcılar asılıdır, bu təsnifatın işinə mane olur._\n",
    "\n",
    "_Keçən dəfə ki bəhsimizdə olduğu kimi naive bayes modelimizi əvvəlcə çağıracağıq daha sonra x,y təyin edəcəyik modeli uyğunlaşdırdıqdan sonra test üçün məlumatımzı daxil edib ehtimalmızı tapacağıq._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB \n",
    "clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris_dataset = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_dataset['data'], iris_dataset['target'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Təxmin olundu: ['setosa']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_new = np.array([[5, 2.9, 1, 0.2]])\n",
    "prediction = clf.predict(X_new)\n",
    "print(\"Təxmin olundu: {}\".format(iris_dataset['target_names'][prediction]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Yadınızdadısa KNN modeli 97.3 faiz düzgün tapmışdı. Ümumiyyətlə Naive Bayes həm təlim, həm də proqnoz vermək üçün son dərəcə sürətlidirlər, düzgün proqnoz verirlər , onlar çox vaxt asanlıqla şərh olunur onların tənzimlənən parametrləri çox azdır_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

